<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <title>Project: CellPainTR Foundation Model</title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
  <style>
    body { font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; max-width: 900px; margin: 0 auto; padding: 40px 20px; line-height: 1.7; color: #333; background: #fff; }
    h1 { font-size: 2.4em; color: #1a1a1a; margin-bottom: 0.2em; font-weight: 700; }
    h2 { font-size: 1.6em; color: #2c3e50; margin-top: 2.5em; margin-bottom: 1.2em; font-weight: 600; border-bottom: 2px solid #3498db; padding-bottom: 0.3em; }
    h3 { font-size: 1.2em; color: #34495e; margin-bottom: 0.5em; font-weight: 600; }
    p, ul { margin-bottom: 1em; font-size: 1.05em; text-align: justify;}
    a { color: #3498db; text-decoration: none; font-weight: 500; }
    a:hover { text-decoration: underline; }
    .main-header { text-align: center; margin-bottom: 50px; padding-bottom: 30px; border-bottom: 1px solid #eee; }
    .project-meta { text-align: center; color: #555; margin-bottom: 2em; }
    .project-meta span { margin: 0 15px; }
    .project-meta a { font-weight: 600; }
    .back-link { display: block; text-align: center; margin-bottom: 40px; font-weight: 600; }
    figure { margin: 2.5em 0; text-align: center; }
    figcaption { font-size: 0.9em; color: #7f8c8d; margin-top: 0.8em; line-height: 1.5; max-width: 80%; margin-left: auto; margin-right: auto;}
    img, video { max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
  </style>
</head>
<body>

  <header class="main-header">
    <h1>CellPainTR: A Foundational Model for Cell Painting</h1>
    <p style="font-size: 1.15em; color: #555; margin: 0.5em 0 1.5em 0; text-align: center;">Generalizable Representation Learning for Cross-Dataset Biological Analysis</p>

    <div class="project-meta">
      <span><strong>Authors:</strong> CÃ©dric Caruzzo, Jong Chul Ye</span>
      <span><a href="https://github.com/CellPainTR/CellPainTR" target="_blank">[GitHub Repository]</a></span>
    </div>
  </header>

  <a href="../blog.html" class="back-link">&larr; Back to Projects & Writing Hub</a>

  <section id="introduction">
    <h2>The Challenge: A "Tower of Babel" in Biological Data</h2>
    <p>
      Cell Painting is a powerful technique that allows scientists to see how cells react to drugs and genetic changes, generating rich, detailed images. Large-scale projects like the JUMP Cell Painting consortium are creating massive datasets with the goal of building a unified "atlas" of cellular biology.
    </p>
    <p>
      However, a critical roadblock prevents this: <strong>batch effects</strong>. These are non-biological variations that arise from differences in labs, equipment, and even day-to-day conditions. They act like different "dialects," distorting the data and making it nearly impossible to compare experiments from different sources. Traditional correction methods like ComBat and Harmony can clean up a static dataset, but they can't generalize. If new data arrives, the entire process must start over, making a truly scalable atlas impossible.
    </p>
  </section>

  <section id="solution">
    <h2>Our Solution: CellPainTR, A Generalizable Transformer</h2>
    <p>
      To solve this, we developed CellPainTR, a Transformer-based model designed not just to correct data, but to learn a universal, foundational understanding of cellular morphology. It learns a representation that is robust to batch effects, allowing for true cross-study analysis.
    </p>
    <figure>
        <img src="../img/proj_cellpaintr/concept_v2.png" alt="Conceptual overview of the CellPainTR workflow">
        <figcaption><strong>The CellPainTR Framework.</strong> Our model (c) takes the feature vectors generated by standard Cell Painting analysis (a, b) and learns a corrected, generalizable representation. The key is the learnable "source context token," which teaches the model about the data's origin, allowing it to disentangle technical noise from true biology.</figcaption>
    </figure>
    
    <h3>The Training Curriculum: A Three-Step Journey</h3>
    <p>
      We train CellPainTR using a carefully designed three-step curriculum to systematically build its understanding.
    </p>
    <ul>
        <li><strong>Step 1 (Self-Supervised Pre-training):</strong> The model first learns the fundamental grammar of cellular morphology by predicting masked features, similar to how language models like BERT learn language.</li>
        <li><strong>Step 2 (Intra-Source Fine-tuning):</strong> Using contrastive learning, the model learns to group similar biological signals together while ignoring noise (like plate-to-plate variation) within a single data source.</li>
        <li><strong>Step 3 (Inter-Source Generalization):</strong> In the final stage, the model is shown data from multiple sources at once. It learns to create a globally consistent representation, effectively translating all data "dialects" into a single, universal language.</li>
    </ul>
    <figure>
        <img src="../img/proj_cellpaintr/training_v2.png" alt="Diagram of the three-step training curriculum">
        <figcaption>The model is progressively trained, first learning general features via reconstruction (Step 1), then refining its understanding within single sources (Step 2), and finally learning a source-invariant representation by mixing data from multiple sources (Step 3).</figcaption>
    </figure>
  </section>

  <section id="results">
    <h2>Results: State-of-the-Art Performance and True Generalization</h2>
    <p>
      On the large-scale JUMP dataset, CellPainTR achieved state-of-the-art performance, demonstrating a superior balance of removing batch effects while preserving the important biological signals. The visualizations below show how the uncorrected data (left) is completely separated by its source (bottom row). After our full training process (right), the sources are seamlessly integrated, while the distinct biological categories (MoA, top row) remain clearly defined.
    </p>
    <figure>
        <img src="../img/proj_cellpaintr/UMAP Comp.png" alt="UMAP comparison of uncorrected vs corrected data">
        <figcaption><strong>Visual Proof.</strong> Top row is colored by biological class (MoA), bottom by data source. The final CellPainTR model (right) successfully mixes the sources while keeping the biological clusters distinct.</figcaption>
    </figure>

    <h3>The Critical Test: Out-of-Distribution Performance</h3>
    <p>
      The true measure of a foundational model is its ability to work on data it has never seen before. We tested CellPainTR on the Bray et al. (2017) datasetâ€”a completely new dataset from a different lab with a different data structure. Without any retraining or fine-tuning, CellPainTR dramatically outperformed all baseline methods, including those that were re-fit specifically for this new data. This powerful result shows that CellPainTR learns a truly robust and generalizable representation of cellular morphology.
    </p>
  </section>
  
  <section id="impact">
    <h2>Broader Impact: Towards a "Cell-BERT" for Biology</h2>
    <p>
      CellPainTR is a proof-of-concept for a new class of models in computational biology. Its ability to generalize suggests we can build a universal, pre-trained model for cellular morphologyâ€”a "Cell-BERT"â€”that could serve as a standard reference for the entire field. Researchers could process new, smaller-scale experiments through this model to instantly place their findings into the context of a massive, unified biological atlas. This would dramatically accelerate discovery and lower the barrier to entry for robust, cross-study analysis.
    </p>
  </section>

  <section id="code">
      <h2>Code & Resources</h2>
      <p style="text-align: center;">The complete source code and instructions to reproduce our results are available on GitHub.</p>
      <p style="text-align: center; margin-top: 1.5em;">
          <a href="https://github.com/CellPainTR/CellPainTR" target="_blank" style="background-color: #2c3e50; color: white; padding: 12px 25px; border-radius: 8px; font-weight: 600;">View on GitHub</a>
      </p>
  </section>

  <a href="../blog.html" class="back-link" style="margin-top: 50px;">&larr; Back to Projects & Writing Hub</a>

</body>
</html>
