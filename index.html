<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <title>CÃ©dric Caruzzo | Research Scientist</title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>">
  <style>
    body { font-family: "Inter", -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; max-width: 900px; margin: 0 auto; padding: 40px 20px; line-height: 1.7; color: #333; background: #fff; }
    h1 { font-size: 2.4em; color: #1a1a1a; margin-bottom: 0.2em; font-weight: 700; }
    h2 { font-size: 1.6em; color: #2c3e50; margin-top: 2.5em; margin-bottom: 1.2em; font-weight: 600; border-bottom: 2px solid #3498db; padding-bottom: 0.3em; }
    h3 { font-size: 1.2em; color: #34495e; margin-bottom: 0.5em; font-weight: 600; }
    header { text-align: center; margin-bottom: 50px; padding-bottom: 30px; border-bottom: 1px solid #eee; }
    .subtitle { font-size: 1.15em; color: #555; margin: 0.5em 0 1.5em 0; }
    .affiliation { font-size: 1.05em; color: #2c3e50; margin-bottom: 1em; }
    .affiliation a { color: #3498db; text-decoration: none; font-weight: 600; }
    .affiliation a:hover { text-decoration: underline; }
    .profile-pic { width: 150px; height: 150px; border-radius: 50%; object-fit: cover; margin: 20px auto; display: block; border: 4px solid #3498db; box-shadow: 0 4px 8px rgba(0,0,0,0.1); }
    nav { margin-top: 25px; font-size: 1em; }
    nav a { margin: 0 12px; text-decoration: none; color: #3498db; font-weight: 500; transition: color 0.2s; }
    nav a:hover { color: #2980b9; text-decoration: underline; }
    section { margin-bottom: 3em; text-align: justify; }
    p, ul { margin-bottom: 1em; font-size: 1.05em; }
    .research-focus-item { margin-bottom: 1.2em; }
    .experience-item, .publication-item { margin-bottom: 2em; padding-bottom: 1.5em; border-bottom: 1px solid #eee; }
    .experience-item:last-child, .publication-item:last-child { border-bottom: none; }
    .institution { font-weight: 600; color: #2c3e50; font-size: 1.1em; }
    .position { color: #34495e; font-style: italic; margin-bottom: 0.5em; }
    .position a { color: #34495e; text-decoration: underline; } /* Style for supervisor links */
    .duration { color: #7f8c8d; font-size: 0.9em; margin-bottom: 0.8em; }
    .experience-item ul { list-style-type: disc; padding-left: 20px; margin-top: 10px; }
    .experience-item li { margin-bottom: 0.5em; }
    .experience-item li a { color: #333; font-weight: 500; } /* Style for links inside list items */
    .projects table { width: 100%; border-collapse: collapse; margin-top: 1em; font-size: 1.02em; }
    .projects th { background: #f8f9fa; color: #2c3e50; padding: 12px; text-align: left; font-weight: 600; border-bottom: 2px solid #3498db; }
    .projects td { border-bottom: 1px solid #eee; padding: 12px; vertical-align: top; }
    .projects tr:hover { background: #f9f9f9; }
    .project-title a { color: inherit; text-decoration: none; font-weight: 600; }
    .project-title a:hover { color: #3498db; text-decoration: underline; }
    .project-contribution { font-size: 1em; margin-top: 4px; }
    .project-methods { font-size: 0.9em; color: #7f8c8d; margin-top: 5px; font-family: monospace; }
    footer { margin-top: 60px; padding-top: 30px; text-align: center; font-size: 0.9em; color: #7f8c8d; border-top: 1px solid #eee; }
    .social-links { margin-top: 25px; display: flex; justify-content: center; gap: 10px; align-items: center; }
    .social-links a { display: inline-block; transition: transform 0.2s; }
    .social-links a:hover { transform: scale(1.1); }
    .social-links img { height: 32px; }
    .publication-title { font-weight: 600; font-size: 1.1em; margin-bottom: 5px; }
    .publication-authors { font-style: italic; color: #555; margin-bottom: 5px; }
    .publication-venue { font-size: 0.95em; color: #7f8c8d; margin-bottom: 10px; }
    .publication-links a { margin-right: 15px; font-weight: 500; color: #3498db; text-decoration: none; font-size: 0.95em; }
    .publication-links a:hover { text-decoration: underline; }
    @media (max-width: 768px) {
      body { padding: 20px 15px; }
      h1 { font-size: 2em; }
      nav a { margin: 0 8px; display: inline-block; margin-bottom: 5px; }
      .projects table { font-size: 0.95em; }
      section { text-align: left; }
    }
  </style>
</head>
<body>

<header>
  <h1>CÃ©dric Caruzzo</h1>
  <img src="img/profile.jpeg" alt="CÃ©dric Caruzzo" class="profile-pic">
  <div class="affiliation">
    AI Research Scientist at <a href="https://lunit.io/" target="_blank">Lunit Inc.</a>
  </div>
  <p class="subtitle">
    Developing new methods for representation learning on large-scale, multimodal scientific data.
  </p>
  <div class="social-links">
    <a href="mailto:cedric.caruzzo@lunit.io" title="Email"><img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/></a>
    <a href="https://scholar.google.com/citations?user=0M8qZDsAAAAJ&hl=fr" target="_blank" title="Google Scholar"><img src="https://img.shields.io/badge/Google_Scholar-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" alt="Google Scholar"/></a>
    <a href="https://github.com/CedricCaruzzo" target="_blank" title="GitHub"><img src="https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/></a>
    <a href="https://www.linkedin.com/in/cedric-caruzzo/" target="_blank" title="LinkedIn"><img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/></a>
  </div>
  <nav>
    <a href="#about">About</a>
    <a href="#publications">Publications</a>
    <a href="#experience">Experience</a>
    <a href="#projects">Projects</a>
  </nav>
</header>

<section id="about">
  <h2>About Me</h2>
  <p>
    My research is centered on building <strong>robust and efficient foundation models</strong> for visual understanding, especially in complex scientific domains. I am driven by the challenge of learning from large-scale, unlabeled data, using domains like digital pathology as a testbed. These gigapixel images provide a unique opportunity to develop scalable architectures and self-supervised methods that learn <strong>dense feature representations</strong> without direct supervision.
  </p>
  <p>
    A primary goal of my work is to develop models that generalize effectively and can be fine-tuned to numerous downstream tasks with minimal data. This involves not only creating powerful visual learners but also exploring how to leverage <strong>multimodality</strong>. I have a strong interest in <strong>alignment</strong>â€”specifically, in designing frameworks that fuse and align unstructured visual data with structured modalities like genomics or chemical representations to build more comprehensive and predictive models of complex systems. Furthermore, I am deeply interested in ensuring that as these models scale, their learned objectives are robustly aligned with human intent, preventing unintended behaviors and ensuring reliable real-world performance.
  </p>
</section>

<section id="research">
  <h2>Research Focus</h2>
  <div class="research-focus-item">
    <h3>Robust and Scalable Foundation Models</h3>
    <p>Designing novel vision architectures and self-supervised learning objectives to train powerful foundation models on massive, unlabeled datasets, with a focus on computational and memory efficiency.</p>
  </div>
  <div class="research-focus-item">
    <h3>Multimodal Fusion and Alignment</h3>
    <p>Developing methods to align dense visual representations with other data modalities (e.g., text, genomics, graphs) to enable zero-shot reasoning and unlock more powerful predictive capabilities.</p>
  </div>
  <div class="research-focus-item">
    <h3>Efficient Fine-Tuning and Generalization</h3>
    <p>Investigating techniques like parameter-efficient fine-tuning (PEFT) and domain adaptation to ensure that large pre-trained models can be quickly and effectively applied to a wide range of specialized downstream tasks.</p>
  </div>
  <div class="research-focus-item">
    <h3>Human-Intent Alignment and Reliability</h3> <p>Moving beyond simple objective functions to ensure model behavior is robustly aligned with the true, often nuanced, goals of a task. This includes exploring preference learning methods to build more predictable and trustworthy AI systems.</p>
  </div>
  <div class="research-focus-item">
    <h3>Representation Learning for Scientific Discovery</h3>
    <p>Applying these core principles to challenging, high-impact scientific domains like digital pathology and high-content screening to accelerate discovery and build more reliable systems.</p>
  </div>
</section>

<section id="publications">
  <h2>Publications</h2>
  <div class="publication-item">
    <div class="publication-title">Wolbachia detection in Aedes aegypti using MALDI-TOF MS coupled to artificial intelligence</div>
    <div class="publication-authors">Antsa Rakotonirina, <strong>CÃ©dric Caruzzo</strong>, et al.</div>
    <div class="publication-venue">Scientific Reports, 2021</div>
    <div class="publication-links">
      <a href="http://dx.doi.org/10.1038/s41598-021-00888-1" target="_blank">[Paper]</a>
    </div>
  </div>

  <div class="publication-item">
    <div class="publication-title">Cellular Phenotypic Profiling Combining Live Imaging & Cell Painting Techniques</div>
    <div class="publication-authors">Soonju Park, <strong>CÃ©dric Caruzzo</strong>, et al.</div>
    <div class="publication-venue">Poster presented at: SLAS Europe 2024 Conference and Exhibition, Barcelona, Spain</div>
    <div class="publication-links">
      <a href="pdf/poster/Live-cell-painting-Institut-Pasteur-Korea.pdf" target="_blank">[Poster PDF]</a>
    </div>
  </div>

</section>

<section id="experience">
  <h2>Experience</h2>
  <div class="experience-item">
    <div class="institution">Lunit Inc.</div>
    <div class="position">AI Research Scientist</div>
    <div class="duration">Mar 2025 â€” Present</div>
    <ul>
      <li>Designing and training large-scale vision foundation models for digital histopathology.</li>
      <li>Developing scalable, distributed inference systems for clinical-scale workloads.</li>
      <li>Crafting theory-grounded data curation strategies to improve model reliability and generalization.</li>
    </ul>
  </div>
  <div class="experience-item">
    <div class="institution">KAIST, Graduate School of AI</div>
    <div class="position">Master's Student (Advisor: <a href="https://scholar.google.com/citations?user=HNMjoNEAAAAJ&hl=en" target="_blank">Prof. Ye Jong Chul</a>)</div>
    <div class="duration">Feb 2023 â€” Mar 2025</div>
    <ul>
      <li>Thesis: <em>Development of Foundation Models in the Context of Cell Painting <a href="https://library.kaist.ac.kr/search/detail/view.do?bibCtrlNo=1122202&flag=dissertation" target="_blank">[Thesis]</a></em></li>
      <li>Developed foundation models for Cell Painting to automate phenotype profiling in drug discovery.</li>
      <li>Designed bidirectional generative models for cross-modal translation between visual phenotypes and chemical structures.</li>
      <li>Investigated methods to mitigate batch effects and improve data harmonization for large-scale bio-imaging.</li>
    </ul>
  </div>
  
  <div class="experience-item">
    <div class="institution">Institut Pasteur Korea & Institut Pasteur Paris</div>
    <div class="position">Data Scientist (Part-time), Pasteur International Unit AI3D</div>
    <div class="duration">Feb 2023 â€” Dec 2024</div>
    <ul>
      <li>Continued core development responsibilities on a part-time basis (40 hours/month) after transitioning to full-time Master's studies.</li>
      <li>Led the ongoing implementation and extension of the institute's primary AI analysis pipeline for high-content screening.</li>
    </ul>
  </div>

  <div class="experience-item">
    <div class="institution">Institut Pasteur Korea & Institut Pasteur Paris</div>
    <div class="position">Data Scientist, Pasteur International Unit AI3D</div>
    <div class="duration">Oct 2021 â€” Feb 2023</div>
    <ul>
      <li>Worked within the Pasteur International Unit (PIU) AI3D, a joint initiative between Institut Pasteur Korea (lead: <a href="https://scholar.google.com/citations?user=8xzsh0wAAAAJ&hl=en" target="_blank">Dr. Spencer Shorte</a>) and Institut Pasteur Paris (lead: <a href="https://scholar.google.com/citations?user=cPAja4UAAAAJ&hl=en" target="_blank">Dr. Christophe Zimmer</a>).</li>
      <li>Designed and implemented the instituteâ€™s primary analysis pipeline for high-content screening, boosting throughput and reproducibility.</li>
      <li>Applied computer vision models to Cell Painting assays to improve phenotypic profiling for drug discovery campaigns.</li>
    </ul>
  </div>

  <div class="experience-item">
    <div class="institution">Institut Pasteur New Caledonia / ISEA</div>
    <div class="position">Research Intern, Undergraduate (Supervisor: <a href="https://scholar.google.com/citations?user=I3ysxxkAAAAJ&hl=en" target="_blank">Prof. Nazha Selmaoui-Folcher</a>)</div>
    <div class="duration">Oct 2020 â€” Oct 2021</div>
    <ul>
        <li>Developed novel feature extraction and classification methods (CNNs, ML classifiers) for high-dimensional MALDI-TOF mass spectrometry data.</li>
        <li>Created an interpretable deconvolution framework to identify discriminative biomarkers for pathogen detection.</li>
    </ul>
  </div>
</section>

<section id="projects">
  <h2>Selected Projects</h2>
  <table>
    <thead>
      <tr>
        <th>Project / Contribution</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="project-title">
          <a href="https://github.com/CellPainTR/CellPainTR" target="_blank">Foundation Model for Cell Painting (CellPainTR)</a>
        </td>
        <td class="project-contribution">
          A novel contrastive learning framework to explicitly disentangle biological signals from nuisance variables (batch effects) in high-content imaging.
          <div class="project-methods">Transformers, Self-Supervised Learning</div>
        </td>
      </tr>
      <tr>
        <td class="project-title">
          <a href="https://github.com/CedricCaruzzo/Racial-Bias-Removal-for-Face-Age-Progression/" target="_blank">Mitigating Racial Bias in Face Age Progression</a>
          </td>
        <td class="project-contribution">
          An investigation into fairness for generative models. We modified a StyleGAN-based age progression model (SAM) to mitigate racial bias by incorporating a race classifier into the training process, promoting more equitable transformations across demographics.<a href="project_fairness.html" class="back-link" style="margin-top: 50px;">[Blog]</a>
          <div class="project-methods">Generative Models, Fairness in AI, StyleGAN, Computer Vision</div>
        </td>
      </tr>
    </tbody>
  </table>
</section>

<section id="contact">
  <h2>Contact</h2>
  <p>
    I'm always interested in discussing new ideas in multimodal learning and self-supervision. I'm keen to connect with students and researchers working on similar problems. Don't hesitate to get in touch via <a href="mailto:cedric.caruzzo@lunit.io">[Email]</a>.
  </p>
</section>

<footer>
  <p>&copy; 2025 CÃ©dric Caruzzo</p>
</footer>

</body>
</html>